{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 6\n",
    "\n",
    "1. Séries temporelles\n",
    "2. Graphiques avec **pandas**\n",
    "3. Graphiques avec **matplotlib**\n",
    "4. Graphiques avec **seaborn**\n",
    "5. Cartes : **matplotlib**, **plotly** et **ipyleaflet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Séries temporelles\n",
    "\n",
    "Le module datetime :\n",
    "- **date**: date (year, month, day) calendrier Grégorien\n",
    "- **time**: temps (hours, minutes, seconds, microseconds)\n",
    "- **datetime**: timestamp (date + time)\n",
    "- **timedelta**: durée, différence entre 2 dates ou 2 temps (days, hours, minutes, seconds, microseconds)\n",
    "- **tzinfo**: gestion des fuseaux horaires (time zones)\n",
    "\n",
    "Voir : https://docs.python.org/fr/3.7/library/datetime.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Objets temporels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date\n",
    "today = datetime.date.today()\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime\n",
    "now = datetime.datetime.now()\n",
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTC datetime\n",
    "now_utc = datetime.datetime.utcnow()\n",
    "now_utc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timedelta\n",
    "today - datetime.date(2021, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# addition entre une date et un timedelta\n",
    "now + datetime.timedelta(days=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# différence entre une date et un timedelta\n",
    "now - datetime.timedelta(days=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytz\n",
    "from pytz import timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a timezone object\n",
    "tz = timezone('Asia/Shanghai')\n",
    "tz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertion d'un datetime selon un fuseau horaire\n",
    "now.astimezone(tz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Ecriture et lecture\n",
    "\n",
    "- `strftime()` : **F**ormater un datetime selon un format donné\n",
    "- `strptime()` : **P**arser un datetime selon un format donné"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directives | Comments\n",
    "- | -\n",
    "%a | Day of the week abbreviated\n",
    "%A | Day of the week\n",
    "%w | Day of the week 0 = Sunday ... 6 = Saturday\n",
    "%d | Day of month on 2 digits 01, 02, ..., 31\n",
    "%j | Day of year on 3 digits 001, 002, ..., 366\n",
    "%b | Month abbreviated\n",
    "%B | Month name\n",
    "%m | Month on 2 digits 01, 02, ..., 12\n",
    "%U | Number of week in year (Sunday = first day)\n",
    "%W | Number of week in year (Monday = first day)\n",
    "%y | Year without the century on 2 digits 00, 01, ..., 99\t \n",
    "%Y | Year with the century on 4 digits 0001, 0002, ..., 2018, 2019, ..., 9998, 9999\n",
    "%H | Hour over 24 00, 01, ..., 23\n",
    "%I | Hour over 12 01, 02, ..., 12\n",
    "%p | AM or PM\n",
    "%M | Minute on 2 digits 00, 01, ..., 59\n",
    "%S | Second on 2 digits 00, 01, ..., 59\n",
    "%f | Microsecond on 6 digits 000000, 000001, ..., 999999\n",
    "%z | UTC offset +HHMM or -HHMM\n",
    "%Z | Time zone \n",
    "%c | Representation date and temps\n",
    "%x | Representation date\n",
    "%X | Representation time\n",
    "%% | Character %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime\n",
    "now = datetime.datetime.now()\n",
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jour dela semaine\n",
    "now.strftime(\"%A %d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locale\n",
    "# mettre parfois fr_FR ou fr_FR.UTF-8 au lien de fr, etc.\n",
    "import locale\n",
    "#locale.setlocale(locale.LC_ALL, 'am') # armenian\n",
    "#locale.setlocale(locale.LC_ALL, 'ar') # arabic\n",
    "#locale.setlocale(locale.LC_ALL, 'az') # azeri\n",
    "#locale.setlocale(locale.LC_ALL, 'bn') # bengali\n",
    "#locale.setlocale(locale.LC_ALL, 'da') # danish\n",
    "#locale.setlocale(locale.LC_ALL, 'de') # german\n",
    "#locale.setlocale(locale.LC_ALL, 'es') # spanish\n",
    "#locale.setlocale(locale.LC_ALL, 'en') # english\n",
    "#locale.setlocale(locale.LC_ALL, 'fa') # farsi\n",
    "locale.setlocale(locale.LC_ALL, 'fr_FR.utf8') # french\n",
    "#locale.setlocale(locale.LC_ALL, 'ga') # gaelic\n",
    "#locale.setlocale(locale.LC_ALL, 'hi') # hindi\n",
    "#locale.setlocale(locale.LC_ALL, 'he') # hebrew\n",
    "#locale.setlocale(locale.LC_ALL, 'hr') # croatian\n",
    "#locale.setlocale(locale.LC_ALL, 'ig') # igbo\n",
    "#locale.setlocale(locale.LC_ALL, 'it') # italian\n",
    "#locale.setlocale(locale.LC_ALL, 'ja') # japanese\n",
    "#locale.setlocale(locale.LC_ALL, 'lt') # lithuanian \n",
    "#locale.setlocale(locale.LC_ALL, 'ko') # korean\n",
    "#locale.setlocale(locale.LC_ALL, 'nl') # dutch\n",
    "#locale.setlocale(locale.LC_ALL, 'no') # norvegian\n",
    "#locale.setlocale(locale.LC_ALL, 'pt') # portugese\n",
    "#locale.setlocale(locale.LC_ALL, 'ro') # romanian\n",
    "#locale.setlocale(locale.LC_ALL, 'ru') # russian\n",
    "#locale.setlocale(locale.LC_ALL, 'sq') # albanian\n",
    "#locale.setlocale(locale.LC_ALL, 'sr') # serbian\n",
    "#locale.setlocale(locale.LC_ALL, 'th') # thai\n",
    "#locale.setlocale(locale.LC_ALL, 'tr') # turkish\n",
    "#locale.setlocale(locale.LC_ALL, 'uk_UA') # ukrainian\n",
    "#locale.setlocale(locale.LC_ALL, 'vi') # vietnamian\n",
    "#locale.setlocale(locale.LC_ALL, 'zh') # chinese\n",
    "now.strftime(\"%A %B %d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lecture au format : AA-MM-DD-HH-MM\n",
    "# écriture au format : HH:MM DD/MM/YYYY\n",
    "var = datetime.datetime.strptime(\"20-11-04-10-30\", \"%y-%m-%d-%H-%M\")\n",
    "var.strftime(\"%H:%M %d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice n° 1**\n",
    "\n",
    "\n",
    "- Prendre le DataFrame des villes 'cities500.txt', combien a-t-on de fuseaux horaires ?\n",
    "- Remplacez les valeurs de la colonne \"timezone\" par des objets \"timezone\".\n",
    "- Prenez le datetime courant (now), convertissez-le avec toutes les valeurs de la colonne \"timezone\", et produisez des chaines de caractères au format format: `'%Y-%m-%d %H:%M:%S'`\n",
    "- Il y a 24 heures dans une journée, combien obtient-on de fuseaux horaires différents ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cities500.zip',\n",
    "                 sep='\\t',\n",
    "                 header=None,\n",
    "                 keep_default_na=False,  # NA = North America\n",
    "                 na_values=['', -9999],\n",
    "                 names=['geonameid', 'name', 'asciiname', 'alternatenames', 'latitude', \n",
    "                        'longitude', 'feature class', 'feature code', 'country code', \n",
    "                        'cc2', 'admin1 code', 'admin2 code', 'admin3 code', 'admin4 code', \n",
    "                        'population', 'elevation', 'dem', 'timezone', 'modification date'],\n",
    "                dtype={'admin1 code': str,\n",
    "                       'admin2 code': str,\n",
    "                       'admin3 code': str,\n",
    "                       'admin4 code': str})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Séries temporelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_taux_change(devises):\n",
    "    df = pd.read_csv(\"Webstat_Export.csv\",\n",
    "                     sep=\";\",\n",
    "                     na_values='-',\n",
    "                     decimal=',',\n",
    "                     skiprows=[0, 1, 3, 4, 5],  # le skiprows permet à l'option \"decimal\" de fonctionner\n",
    "                     converters={0: lambda x: pd.to_datetime(x, format='%d/%m/%Y', errors='ignore')})\n",
    "\n",
    "    # extraction des codes monnaies\n",
    "    cols = pd.Series(df.columns.tolist()).str.extract('\\(([A-Z]{3})\\)', expand=True)\n",
    "    cols.iloc[0] = 'Date'\n",
    "    df.columns = cols[0]\n",
    "\n",
    "    # selection des devises\n",
    "    df = df[['Date'] + devises]\n",
    "\n",
    "    # drop na\n",
    "    df = df.dropna()\n",
    "\n",
    "    # set and sort index\n",
    "    df = df.set_index('Date')\n",
    "    df = df.sort_index()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_taux_change(['USD', 'CHF', 'GBP', 'JPY', 'RUB', 'CNY'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**L'accesseur dt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset_index\n",
    "df = df.reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access to year\n",
    "df['Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access to month\n",
    "df['Date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access to week days\n",
    "df['Date'].dt.weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sélection de données temporelles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the index as a datetime object\n",
    "df = df.set_index('Date')\n",
    "df = df.sort_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yearly data\n",
    "df.loc['2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monthly data\n",
    "df.loc['2020/01'] # or df.loc['01/2020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice selection\n",
    "df.loc['12/2019':'01/2020']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réindexation temporelle\n",
    "\n",
    "La fonction `date_range()` permet de construire un nouvel index sur la base de limites et d'une fréquence donnée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nouvel index avec toutes les dates\n",
    "newindex = pd.date_range(start=df.index[0], end=df.index[-1], freq='D')\n",
    "newindex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode reindex() va produire un nouveau DataFrame avec des valeurs manquantes si le nouvel index comprend des valeurs nouvelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# réindexation temporelle\n",
    "var = df.reindex(newindex)\n",
    "var.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Différentes méthodes permettent de combler les valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna forward\n",
    "var.fillna(method='ffill').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna backward\n",
    "var.fillna(method='bfill').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode interpolate() remplace les valeurs manquantes par une interpolation linéraire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate \n",
    "var.interpolate().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy linspace\n",
    "np.linspace(0, 100, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate linear = numpy.linspace (lignes 1 et 4 pour ligne 2 et 3)\n",
    "array = np.linspace(var.iloc[1], var.iloc[4], 4)\n",
    "pd.DataFrame(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Agrégations temporelles**\n",
    "\n",
    "Méthode `resample()` qui se comporte comme un groupby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yearly aggregation\n",
    "df.resample('A').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yearly aggregation\n",
    "df.resample('A').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monthly aggregation\n",
    "df.resample('MS').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monthly aggregation\n",
    "df.resample('MS').apply(lambda x: x.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alias | Offset type | Description\n",
    "- | - | -\n",
    "D | Day | Calendar daily\n",
    "B | BusinessDay | Business daily\n",
    "H | Hour | Hourly\n",
    "T or min | Minute | Minutely\n",
    "S | Second | Secondly\n",
    "L or ms | Milli | Millisecond (1/1000th of 1 second)\n",
    "U | Micro | Microsecond (1/1000000th of 1 second)\n",
    "M | MonthEnd | Last calendar day of month\n",
    "BM | BusinessMonthEnd | Last business day (weekday) of month\n",
    "MS | MonthBegin | First calendar day of month\n",
    "BMS | BusinessMonthBegin | First weekday of month\n",
    "W-MON, W-TUE, ... | Week | Weekly on given day of week: MON, TUE, WED, THU, FRI, SAT, or SUN.\n",
    "Q-JAN, Q-FEB, ... | QuarterEnd | Quarterly dates anchored on last calendar day of each month,for year ending in indicated month: JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, NOV, or DEC.\n",
    "A-JAN, A-FEB, ... | YearEnd | Annual dates anchored on last calendar day of given month: JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, NOV, or DEC.\n",
    "\n",
    "Source: Python for Data Analysis, Wes McKinney, O'Reilly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Graphiques temporels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taux de change\n",
    "df.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taux de change divisés par leur moyenne\n",
    "(df / df.mean()).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taux de change divisés par leur moyenne avec une moyenne glissante de 30 jours\n",
    "(df / df.mean()).rolling(30).mean().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice n° 2**\n",
    "\n",
    "Affichez les taux de change divisés par la dernière valeur connue avec une moyenne glissante de 30 jours.\n",
    "\n",
    "Affichez les taux de change divisés par leur moyenne avec un maximum glissant sur 100 jours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sparklines**\n",
    "\n",
    "```bash\n",
    "$ pip install sparklines\n",
    "```\n",
    "\n",
    "Une *sparkline* est une visualisation de données qui représente la forme générale de l'évolution d'une variable sur une ligne. La *sparkline* est en général insérée dans un texte et dans un tableau.\n",
    "\n",
    "Source : https://fr.wikipedia.org/wiki/Sparkline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparklines\n",
    "\n",
    "# simple API\n",
    "sparkl = lambda x: sparklines.sparklines(x)[0]\n",
    "\n",
    "sparkl(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moyenne et tendance pour USD\n",
    "(df.groupby(pd.Grouper(freq='A'))\n",
    " .agg(USD=('USD', lambda s_: s_.mean().round(3)),\n",
    "      trend_USD=('USD', lambda s_: sparkl(s_.resample('Q').mean())))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moyenne et tendance annuelles pour toutes les devises\n",
    "year = 2021\n",
    "\n",
    "(df.loc[str(year)]\n",
    " .pipe(lambda df_: pd.concat([df_.mean(), (df_.resample('Q')\n",
    "                                           .mean()\n",
    "                                           .apply(sparkl)\n",
    "                                          )],\n",
    "                             axis=1))\n",
    " .rename({0: 'mean', 1:'trend'}, axis=1)\n",
    " .rename_axis(\"devises\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Graphiques avec pandas\n",
    "\n",
    "**pandas** propose une API relativement simple qui s'appuie sur **matplotlib**.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Names US et FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names US\n",
    "def df_names_us():\n",
    "    dfs = []\n",
    "    for year in range(1880, 2020):\n",
    "        csv = pd.read_csv(f'names/yob{year}.txt',\n",
    "                          names=['name', 'gender', 'births'])\n",
    "        csv['year'] = year\n",
    "        dfs.append(csv)\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    df = df[['year', 'name', 'gender', 'births']]\n",
    "    return df\n",
    "\n",
    "df_us = df_names_us()\n",
    "df_us.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names FR\n",
    "def df_names_fr():\n",
    "    # dict for gender\n",
    "    d = {'1': 'M', '2': 'F'}\n",
    "    # read table\n",
    "    # no header\n",
    "    # set columns\n",
    "    # user converters for gender and name\n",
    "    df = pd.read_csv('nat2021_csv.zip',\n",
    "                      sep=';',\n",
    "                      header=0,\n",
    "                      names=['gender', 'name', 'year', 'births'],\n",
    "                      converters={\n",
    "                          'gender': d.get,\n",
    "                          'name': str.title\n",
    "                      })\n",
    "    # select usable data\n",
    "    # name with length > 1\n",
    "    # year != 'XXXX'\n",
    "    # name != '_Prenoms_Rares' (after use of str.title)\n",
    "    df = df.loc[(df['name'].str.len() > 1)\n",
    "                & (df['year'] != 'XXXX')\n",
    "                & (df['name'] != '_Prenoms_Rares')]\n",
    "    # set year type to int\n",
    "    df['year'] = df['year'].astype(int)\n",
    "    # set columns order\n",
    "    df = df[['year', 'name', 'gender', 'births']]\n",
    "    # sort data\n",
    "    df = df.sort_values(['year', 'gender', 'births', 'name'],\n",
    "                   ascending=[True, True, False, True])\n",
    "    # reset index\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "df_fr = df_names_fr()\n",
    "df_fr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice n° 3**\n",
    "\n",
    "Combinez les 2 DataFrames en un seul DataFrame avec une colonne en plus \"country\" valant \"us\" ou \"fr\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a \"country\" column to df_us and df_fr\n",
    "\n",
    "# combine df_us and df_fr into df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemple\n",
    "tab = df.loc[(df['country'] == 'us') & (df['name'] == 'Emma') & (df['gender'] == 'F')]\n",
    "tab = tab.set_index('year')\n",
    "tab['births'].plot(title='Nombre de naissances pour Emma (F) - us');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemple\n",
    "tab = df.loc[(df['country'] == 'fr') & (df['name'] == 'Emma') & (df['gender'] == 'F')]\n",
    "tab = tab.set_index('year')\n",
    "tab['births'].plot(title='Nombre de naissances pour Emma (F) - fr');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quelques fonctions\n",
    "def select(country, name, gender):\n",
    "    return df.loc[(df['country'] == country) &\n",
    "                  (df['name'] == name) &\n",
    "                  (df['gender'] == gender)]\n",
    "\n",
    "def plot_names(country, name, gender):\n",
    "    tab = select(country, name, gender)\n",
    "    tab = tab.set_index('year')\n",
    "    tab['births'].plot(title=f'Nombre de naissances pour {name} ({gender}) - {country}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_names('us', 'Linda', 'F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice n° 4**\n",
    "\n",
    "Afficher l'évolution du nombre de naissances US ou FR par année et par genre.\n",
    "\n",
    "Afficher l'évolution de la diversité des prénoms US ou FR par année et par genre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**bar plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sélection + pivot\n",
    "top10 = ['Camille', 'Louise', 'Léa', 'Ambre', 'Agathe',\n",
    "         'Louis', 'Gabriel', 'Léo', 'Maël', 'Paul']\n",
    "selection = df.loc[(df['year'] == 2020) & (df['country'] == 'fr') & df['name'].isin(top10)]\n",
    "tab = selection.pivot_table(values='births',\n",
    "                      index='name',\n",
    "                      aggfunc='sum')\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot\n",
    "tab.plot(kind='bar', rot=60);  # testez avec barh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barh plot\n",
    "tab.sort_values('births').plot(kind='barh');  # testez avec barh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pie plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sélection + pivot\n",
    "selection = df.loc[df['name']=='Jean']\n",
    "tab = selection.pivot_table(values='births',\n",
    "                            index='gender',\n",
    "                            aggfunc='sum')\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection.groupby('gender')['births'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie plot\n",
    "tab.plot(kind='pie',\n",
    "         y='births',\n",
    "         colors=['m', 'c'],\n",
    "         autopct='%1.2f%%',\n",
    "         textprops={'color': 'w', 'weight': 'bold'},\n",
    "         explode=(0.0, 0.05));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Graphiques avec matplotlib\n",
    "\n",
    "- Objet principal : Figure\n",
    "- Sous-graphiques : Axes à ne pas confondre avec les axes (axis en anglais)\n",
    "\n",
    "Méthodes :\n",
    "- `add_subplot(ligne, colonne, n° de figure)` ou 111, 121, 122, 221, 222, 223, 224... si < 10, par sous-graphique\n",
    "- `subplots(nb lignes, nb colonnes)` pour tous les sous-graphiques\n",
    "\n",
    "On utilise la sous-librairie pyplot.\n",
    "\n",
    "Voir : https://matplotlib.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plusieurs courbes en un grahique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plusieurs courbes en un grahique\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "name, gender = 'Emma', 'F'\n",
    "\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.set_title(f'Nombre de naissances pour {name} ({gender})')\n",
    "\n",
    "country = 'us'\n",
    "tab = select(country, name, gender)\n",
    "tab = tab.set_index('year')\n",
    "b = tab['births']\n",
    "mean_us = b.mean()\n",
    "ax1.plot(b);\n",
    "\n",
    "xmax = tab['births'].idxmax()\n",
    "ymax = tab['births'].max()\n",
    "ax1.annotate('max us',\n",
    "             xy=(xmax, ymax),\n",
    "             xytext=(xmax, ymax+50),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.01))\n",
    "\n",
    "country = 'fr'\n",
    "tab = select(country, name, gender)\n",
    "tab = tab.set_index('year')\n",
    "b = tab['births']\n",
    "mean_fr = b.mean()\n",
    "ax1.plot(b);\n",
    "\n",
    "ax1.axhline(y=mean_us, color='b', ls=':')\n",
    "ax1.axhline(y=mean_fr, color='r', ls=':')\n",
    "\n",
    "xmax = tab['births'].idxmax()\n",
    "ymax = tab['births'].max()\n",
    "ax1.annotate('max fr',\n",
    "             xy=(xmax, ymax),\n",
    "             xytext=(xmax, ymax+50),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.01))\n",
    "\n",
    "ax1.legend(['us', 'fr']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plusieurs grahiques avec add_subplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_country_name_gender(country, name, gender, ax):\n",
    "    tab = select(country, name, gender)\n",
    "    tab = tab.set_index('year')\n",
    "    ax.set_title(country)\n",
    "    ax.plot(tab['births']);\n",
    "      \n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "name, gender = 'Emma', 'F'\n",
    "\n",
    "fig.suptitle(f'Nombre de naissances pour {name} ({gender})')\n",
    "\n",
    "country = 'us'\n",
    "ax1 = fig.add_subplot(121)\n",
    "plot_country_name_gender(country, name, gender, ax1)\n",
    "\n",
    "country = 'fr'\n",
    "ax2 = fig.add_subplot(122)\n",
    "plot_country_name_gender(country, name, gender, ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plusieurs grahiques avec subplots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_country_name_gender(country, name, gender, ax):\n",
    "    tab = select(country, name, gender)\n",
    "    tab = tab.set_index('year')\n",
    "    ax.set_title(f'{country} ({gender})')\n",
    "    ax.plot(tab['births']);\n",
    "      \n",
    "name = 'Jean'\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.suptitle(f'Nombre de naissances pour {name}')\n",
    "# tableau lignes x colonnes\n",
    "[[ax1, ax2], [ax3, ax4]] = fig.subplots(2, 2, sharex=True, sharey=True)\n",
    "fig.subplots_adjust(hspace=0.3)  # séparation verticale\n",
    "\n",
    "plot_country_name_gender('us', name, 'F', ax1)\n",
    "plot_country_name_gender('fr', name, 'F', ax2)\n",
    "plot_country_name_gender('us', name, 'M', ax3)\n",
    "plot_country_name_gender('fr', name, 'M', ax4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.Axes.plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> plot(x, y, color='green', marker='o', linestyle='dashed',\n",
    "> ...      linewidth=2, markersize=12)\n",
    "\n",
    "Dans **matplotlib** il y a :\n",
    "- 4 types de lignes: '-' (solid), '--' (dashed), ':' (dotted), '-.' (dashdotted)\n",
    "- plusieurs referentiels de couleurs :\n",
    "    - 8 couleurs basiques : 'b' (blue), 'c' (cyan), 'g' (green), 'k' (black), 'm' (magenta), 'r' (red), 'w' (white) and 'y' (yellow)\n",
    "    - niveaux de gris : nombres sous forme de chaines entre '0.0' (noir) et '1.0' (blanc)\n",
    "    - 148 couleurs nommées : voir la variable matplotlib.colors.cnames\n",
    "    - 16+ millions de couleurs RVB en hexadecimal: #xxyyzz\n",
    "- 41 marqueurs : see variable matplotlib.lines.Line2D.markers\n",
    "- linewidth peut être remplacé par lw\n",
    "- linestyle peut être remplacé par ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_country_name_gender(country, name, gender, ax):\n",
    "    tab = select(country, name, gender)\n",
    "    tab = tab.set_index('year')\n",
    "    ax.set_title(f'{country} ({gender})')\n",
    "    ax.plot(tab['births'],\n",
    "            '*' if country=='us' else 'H',\n",
    "            color='m' if gender=='F' else 'c');\n",
    "      \n",
    "name = 'Alix'\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "fig.suptitle(f'Nombre de naissances pour {name}')\n",
    "# tableau lignes x colonnes\n",
    "[[ax1, ax2], [ax3, ax4]] = fig.subplots(2, 2, sharex=True)\n",
    "fig.subplots_adjust(hspace=0.3)  # séparation verticale\n",
    "\n",
    "plot_country_name_gender('us', name, 'F', ax1)\n",
    "plot_country_name_gender('fr', name, 'F', ax2)\n",
    "plot_country_name_gender('us', name, 'M', ax3)\n",
    "plot_country_name_gender('fr', name, 'M', ax4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bar plot customisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sélection + pivot\n",
    "top10 = ['Camille', 'Louise', 'Léa', 'Ambre', 'Agathe',\n",
    "         'Louis', 'Gabriel', 'Léo', 'Maël', 'Paul']\n",
    "selection = df.loc[(df['year'] == 2020) & (df['country'] == 'fr') & df['name'].isin(top10)]\n",
    "tab = selection.pivot_table(values='births',\n",
    "                      index='name',\n",
    "                      aggfunc='sum')\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot\n",
    "plt.bar(x=tab.index, height=tab['births'], color=list('mmmccmmccc'));  # testez avec barh\n",
    "plt.xticks(rotation=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Graphiques avec seaborn\n",
    "\n",
    "Extension de **matplotlib** orientée statistiques.\n",
    "\n",
    "Voir : https://seaborn.pydata.org/api.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### countplot\n",
    "\n",
    "Show the counts of observations in each categorical bin using bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countplot\n",
    "df['initial'] = df['name'].str[0]\n",
    "df = df.sort_values('initial')\n",
    "sns.countplot(data=df, x='initial');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### barplot\n",
    "\n",
    "Show point estimates and confidence intervals as rectangular bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn barplot with births for decades\n",
    "plt.figure(figsize=(8, 5))\n",
    "var = df.loc[df['year'] % 10 == 0]\n",
    "sns.barplot(data=var, x='year', y='births', palette='Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn barplot with births for decades + hue\n",
    "plt.figure(figsize=(8, 5))\n",
    "var = df.loc[df['year'] % 10 == 0]\n",
    "sns.barplot(data=var, x='year', y='births', hue='gender', palette=['m', 'c'], ci=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('year').mean(numeric_only=True).loc[1950]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### displot\n",
    "\n",
    "Flexibly plot a univariate distribution of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of names which appear at least 10,000 times\n",
    "var = df.pivot_table(index='name', values='births', aggfunc='sum')\n",
    "var = var.loc[var['births'] >= 10_000]\n",
    "names10000 = var.index\n",
    "\n",
    "# data for names which appear at least 10,000 times\n",
    "df10000 = df.loc[df['name'].isin(names10000)]\n",
    "print(len(df10000))\n",
    "\n",
    "# number of births by gender, and ratio F / (F + M)\n",
    "var = df10000.pivot_table(index='name',\n",
    "                          columns='gender',\n",
    "                          values='births',\n",
    "                          aggfunc='sum')\n",
    "ratio = var['F'] / (var['F'] + var['M'])\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn distplot\n",
    "var = df.loc[df['year'] % 10 == 0]\n",
    "sns.displot(ratio, kde=False, rug=True, bins=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### regplot\n",
    "\n",
    "Plot data and a linear regression model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select years year1 and year2\n",
    "year1 = 2012\n",
    "year2 = 2021\n",
    "var = df.loc[df[\"year\"].isin([year1, year2])]\n",
    "var = var.pivot_table(values=\"births\",\n",
    "                      index=\"name\",\n",
    "                      columns=\"year\",\n",
    "                      aggfunc='sum')\n",
    "sns.regplot(x=var[year1], y=var[year2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "var = var.dropna()\n",
    "print(linregress(var[2012].values, var[2021].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept, *_ = linregress(var[2012].values, var[2021].values)\n",
    "slope, intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept, _, _, _ = linregress(var[2012].values, var[2021].values)\n",
    "slope, intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stripplot\n",
    "\n",
    "Draw a scatterplot where one variable is categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stripplot horizontal\n",
    "df['terminal'] = df['name'].str[-1].str.upper()\n",
    "letters = list('AEN')\n",
    "var = df.loc[df['terminal'].isin(letters) & (df['year'] > 2000) & (df['country'] == 'us')]\n",
    "sns.stripplot(data=var, x='terminal', y='births');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stripplot vertical\n",
    "var = df.loc[df['terminal'].isin(letters) & (df['year'] > 2000) & (df['country'] == 'fr')]\n",
    "ax = sns.stripplot(data=var, y='terminal', x='births');\n",
    "ax.set_title('Test');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### heatmap\n",
    "\n",
    "Plot rectangular data as a color-encoded matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "sns.heatmap(pd.crosstab(df['terminal'], df['initial']), cmap='Blues', ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = pd.crosstab(df['terminal'], df['initial']).iloc[:5, :5]\n",
    "sns.heatmap(tab, cmap='Blues', annot=True, fmt='d');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cartes : maplotlib, plotly, ipyleaflet\n",
    "\n",
    "### 5.1 Cartes naives avec matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# communes de France\n",
    "\n",
    "df = pd.read_csv('correspondance-code-insee-code-postal.csv',\n",
    "                sep=';')\n",
    "df[['Latitude', 'Longitude']] = df['geo_point_2d'].str.extract('(.*), (.*)').astype(float)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carte naive\n",
    "plt.scatter(df['Longitude'], df['Latitude']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# métro : projection cylindrique équidistante vs Mercator\n",
    "metro = df.loc[df['Latitude'] > 40]\n",
    "plt.scatter(metro['Longitude'], metro['Latitude']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prise en compte du relief."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuancier bleu\n",
    "plt.scatter(metro[\"Longitude\"],\n",
    "            metro[\"Latitude\"],\n",
    "            c=metro[\"Altitude Moyenne\"],\n",
    "            cmap=plt.cm.Blues,\n",
    "            edgecolors='none');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec tri des altitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuancier bleu avec tri des valeurs\n",
    "metro = metro.sort_values(\"Altitude Moyenne\")\n",
    "plt.scatter(metro[\"Longitude\"],\n",
    "            metro[\"Latitude\"],\n",
    "            c=metro[\"Altitude Moyenne\"],\n",
    "            cmap=plt.cm.Blues,\n",
    "            edgecolors='none');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec une autre palette de couleur et une colorbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on utilise plt.cm.Spectral_r\n",
    "var = plt.scatter(x=metro[\"Longitude\"],\n",
    "            y=metro[\"Latitude\"],\n",
    "            c=metro[\"Altitude Moyenne\"],\n",
    "            cmap=plt.cm.Spectral_r,\n",
    "            edgecolors='none')\n",
    "plt.colorbar(var);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque**\n",
    "\n",
    "Il existe dans **matplotlib** (et **seaborn**) un système de palettes de couleurs :\n",
    "\n",
    "- matplotlib : https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
    "\n",
    "- seaborn : http://seaborn.pydata.org/tutorial/color_palettes.html\n",
    "\n",
    "Les librairies gèrent également :\n",
    "\n",
    "- Les palettes de couleurs de **ColorBrewer** : http://colorbrewer2.org\n",
    "\n",
    "- Les 954 couleurs nommées de manière participative par l'initiative **xkcd** : https://xkcd.com/color/rgb/ Voir également le blog : https://blog.xkcd.com/2010/05/03/color-survey-results/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Cartes avec plotly\n",
    "\n",
    "**Plotly** Python Open Source Graphing Library\n",
    "\n",
    "**Plotly**'s Python graphing library makes interactive, publication-quality graphs.\n",
    "\n",
    "Voir : https://plotly.com/python/\n",
    "\n",
    "La société canadienne plotly édite également la librairie **dash**.\n",
    "\n",
    "Voir : https://plotly.com/dash/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from plotly.offline import iplot\n",
    "import colorlover as cl\n",
    "\n",
    "# init if needed\n",
    "# from plotly.offline import init_notebook_mode\n",
    "# init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pays\n",
    "var = pd.read_html('https://www.geonames.org/countries/',\n",
    "                   header=0,\n",
    "                   keep_default_na=False)  # NA = North America\n",
    "df = var[1]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carte mondiale : programmation déclarative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carte mondiale\n",
    "data = [{\n",
    "        'type': 'choropleth',\n",
    "        'locations': df['ISO-3166 alpha3'],\n",
    "        'z': df['Population'],\n",
    "        'text': df['Country'],\n",
    "        'colorscale': list(zip(np.linspace(0, 1, 9), cl.scales['9']['seq']['Reds'])),\n",
    "        'autocolorscale': False,\n",
    "        'reversescale': False,\n",
    "        'marker': {\n",
    "            'line': {\n",
    "                'color': 'rgb(180,180,180)',\n",
    "                'width': 0.5\n",
    "            }},\n",
    "        'colorbar':\n",
    "            {'autotick': False,\n",
    "            'title': 'Population'},\n",
    "        }]\n",
    "\n",
    "layout = {\n",
    "    'title': '<br>Source:\\\n",
    "            <a href=\"https://www.geonames.org/countries/\">\\\n",
    "            geonames</a>',\n",
    "    'geo': {\n",
    "        'showcountries': True,\n",
    "        'showframe': False,\n",
    "        'showcoastlines': False,\n",
    "        'projection': {\n",
    "            'type': 'natural earth'  # 'natural earth'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "fig = {'data': data, 'layout': layout}\n",
    "iplot(fig, validate=False, filename='d3-world-map')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice n° 5**\n",
    "\n",
    "- Ajoutez une colonne 'Densité'\n",
    "- Affichez la densité en niveaux de bleus (cherchez une correction des données pour obtenir un affichage pertinent).\n",
    "- Prenez une projection aléatoire parmi : 'equirectangular', 'mercator', 'orthographic', 'natural earth', 'kavrayskiy7', 'miller', 'robinson', 'eckert4', 'azimuthal equal area', 'azimuthal equidistant', 'conic equal area', 'conic conformal', 'conic equidistant', 'gnomonic', 'stereographic', 'mollweide', 'hammer', 'transverse mercator' en utilisant numpy.random.choice()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cartes choroplèthes\n",
    "\n",
    "Pour produire une carte choroplèthe, il faut récupérer un fichier *geojson* de la partie du monde considérée. Ce fichier contient entre autres 2 informations importantes :\n",
    "- Une clé qui désigne chaque sous-région,\n",
    "- La description d'un polygone ou d'un multi-polygones sous la forme d'une liste de coordonnées (latitudes et longitudes),\n",
    "\n",
    "Il faut ensuite faire correspondre les valeurs de la colonne du DataFrame qui contient les données relatives à chaque sous-région avec celles de la clé du fichier *geojson*.\n",
    "\n",
    "Il est possible ensuite d'utiliser différents fonds de cartes et différents nuanciers.\n",
    "\n",
    "Le fichier \"departements.geojson\" utilisé ci-après provient du site : https://france-geojson.gregoiredavid.fr/ et il faut analyser le fichier pour trouver la clé correspondant à chaque sous-région."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"departements.geojson\") as f:\n",
    "    departements = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste des valeurs de la clé \"code\"\n",
    "codes = sorted([f[\"properties\"][\"code\"] for f in departements[\"features\"]])\n",
    "print(*codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset \n",
    "geo = pd.read_csv(\"correspondance-code-insee-code-postal.csv\",\n",
    "                 sep=\";\",\n",
    "                 )\n",
    "\n",
    "geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population des départements\n",
    "df = (geo.groupby(\"Code Département\", as_index=False)[\"Population\"]\n",
    "      .sum()\n",
    "     )\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choropleth_mapbox\n",
    "px.choropleth_mapbox(data_frame=df,\n",
    "                     geojson=departements,\n",
    "                     locations='Code Département',  # clé dans le DataFrame\n",
    "                     color='Population',\n",
    "                     featureidkey='properties.code',  # accès à la clé dans le fichier geojson\n",
    "                     color_continuous_scale=\"teal\",\n",
    "                     mapbox_style=\"carto-positron\",\n",
    "                     zoom=4.0,\n",
    "                     center = {\"lat\": 47.0, \"lon\": 0.0},\n",
    "                     opacity=0.5,\n",
    "                     labels={'Population': 'Population en milliers'}\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Documentation**\n",
    "\n",
    "- Plotly Express : https://plotly.com/python/plotly-express/\n",
    "- Built-in Continuous Color Scales : https://plotly.com/python/builtin-colorscales/\n",
    "- Mapbox Map Layers : https://plotly.com/python/mapbox-layers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Geocoding avec geopy et cartes avec ipyleaflet\n",
    "\n",
    "**ipyleaflet** provides interactive maps in the Jupyter notebook based on leaflet.js JavaScript library and OpenStreetMap.\n",
    "\n",
    "Installation (in a shell):\n",
    "\n",
    "```bash\n",
    "$ conda install -c conda-forge geopy OU $ pip install geopy\n",
    "\n",
    "$ conda install -c conda-forge ipyleaflet OU $ pip install ipyleaflet\n",
    "\n",
    "$ jupyter nbextension enable --py --sys-prefix ipyleaflet\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**geopy** : informations sur une adresse physique.\n",
    "\n",
    "Voir : https://geopy.readthedocs.io/en/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mandatory if Python ssl.SSLError occurs\n",
    "#import ssl\n",
    "#import certifi\n",
    "#ctx = ssl.create_default_context(cafile=certifi.where())\n",
    "#geopy.geocoders.options.default_ssl_context = ctx\n",
    "#import geopy\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "geolocator = Nominatim(user_agent='telecom_paris', timeout=7)\n",
    "location = geolocator.geocode('19 Place Marguerite Perey, 91120 Palaiseau, France')\n",
    "location.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get latitude and longitude\n",
    "lat, lon = location.raw['lat'], location.raw['lon']\n",
    "lat, lon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo\n",
    "from ipyleaflet import Map\n",
    "\n",
    "# map arround 48.71, 2.20\n",
    "m = Map(center=(lat, lon), zoom=18)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image satellite**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# satellite map\n",
    "from datetime import datetime, timedelta\n",
    "from ipyleaflet import basemaps, basemap_to_tiles\n",
    "\n",
    "# satellite map for yesterday\n",
    "# NASA's Global Imagery Browse Services\n",
    "yesterday = datetime.now() - timedelta(days=1)\n",
    "nasa = basemap_to_tiles(basemaps.NASAGIBS.ModisTerraTrueColorCR, yesterday.strftime('%Y-%m-%d'))\n",
    "m = Map(layers=(nasa, ), center=(lat, lon), zoom=4)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Autre carte...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# villes\n",
    "df = pd.read_csv('cities500.zip',\n",
    "                 sep='\\t',header=None,\n",
    "                 keep_default_na=False,  # NA = North America\n",
    "                 na_values=['', -9999],\n",
    "                 names=['geonameid', 'name', 'asciiname', 'alternatenames', 'latitude', \n",
    "                        'longitude', 'feature class', 'feature code', 'country code',\n",
    "                        'cc2', 'admin1 code', 'admin2 code', 'admin3 code', 'admin4 code',\n",
    "                        'population', 'elevation', 'dem', 'timezone', 'modification date'],\n",
    "                        dtype={'admin1 code': str,\n",
    "                               'admin2 code': str,\n",
    "                               'admin3 code': str,\n",
    "                               'admin4 code': str})\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map with markers\n",
    "\n",
    "from ipyleaflet import Marker, LayerGroup\n",
    "\n",
    "watercolor = basemap_to_tiles(basemaps.Stamen.Watercolor)\n",
    "m = Map(layers=(watercolor, ), center=(50, 50), zoom=1)\n",
    "\n",
    "# add markers for cities with population >= 3M\n",
    "df2 = df.loc[df['population'] >= 3e6]\n",
    "layers = []\n",
    "for i, row in df2.iterrows():\n",
    "    marker = Marker(location=(row['latitude'], row['longitude']),\n",
    "                    draggable=False,\n",
    "                    title=row['name'])\n",
    "    layers.append(marker)\n",
    "layer_group = LayerGroup(layers=layers)\n",
    "m.add_layer(layer_group)\n",
    "\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
