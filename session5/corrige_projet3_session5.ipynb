{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corrigé Projet Maison n° 3 - Session 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. US baby names\n",
    "\n",
    "On va s'intéresser au dataset **National data** de la SSA : https://www.ssa.gov/oact/babynames/limits.html\n",
    "\n",
    "1. Télécharger le dataset des prénoms US : https://www.ssa.gov/oact/babynames/names.zip\n",
    "\n",
    "2. Implémenter une fonction Python `df_names_us()` qui produit un unique DataFrame avec tous les fichiers en utilisant **pandas** (par ex. avec la fonction `pandas.concat()`), pas de bash :)\n",
    "\n",
    "Ordre et noms des colonnes : \"year\", \"name\", \"gender\", \"births\"\n",
    "\n",
    "Le DataFrame doit être trié selon l'année croissante puis selon l'ordre défini dans les différents fichiers (voir la documentation ci-dessus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_names_us():\n",
    "    dfs = [(pd\n",
    "            .read_csv(f\"names/yob{year}.txt\", names=[\"name\", \"gender\", \"births\"])\n",
    "            .assign(year=year))\n",
    "           for year in range(1880, 2022)]\n",
    "    \n",
    "    df = (pd.concat(dfs, ignore_index=True)\n",
    "          .loc[:, [\"year\", \"name\", \"gender\", \"births\"]]\n",
    "         )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_us = df_names_us()\n",
    "df_us.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head\n",
    "df_us.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prénoms français"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va s'intéresser au dataset **Fichiers France hors Mayotte** de l'INSEE :  https://www.insee.fr/fr/statistiques/2540004/\n",
    "\n",
    "L'idée est de charger les données et ensuite de les conformer au DataFrame des prénoms US. Ainsi, toute manipulation sur le DataFrame des prénoms US pourra être directement réutilisée avec le DataFrame des prénoms français.\n",
    " \n",
    "1. Télécharger le dataset des prénoms français : https://www.insee.fr/fr/statistiques/fichier/2540004/nat2021_csv.zip\n",
    "\n",
    "\n",
    "Lire la documentation, ça peut être utile...\n",
    " \n",
    "2. Implémenter une fonction Python qui produit un DataFrame avec les prénoms français en prenant le DataFrame des prénoms US comme modèle :\n",
    " \n",
    " - Même ordre et mêmes noms des colonnes : \"year\", \"name\", \"gender\", \"births\"\n",
    " - Mêmes dtypes pour les colonnes\n",
    " - Mêmes valeurs pour la colonne \"gender\"\n",
    " - Seuls les prénoms de 2 caractères et plus sont conservés\n",
    " - La casse des prénoms doit être identique : initiales en majuscule, autres lettres en minuscule\n",
    " - Les lignes avec des données inutilisables doivent être supprimées\n",
    " - Les données sont triées à l'identique : year (↑), puis gender (↑), puis births (↓) et enfin name (↑)\n",
    " - L'index du DataFrame doit aller de 0 à N-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with converters\n",
    "def df_names_fr():\n",
    "    # genres\n",
    "    mapping = {1:\"M\", 2:\"F\"}\n",
    "    # read_csv\n",
    "    df = pd.read_csv(\"nat2021_csv.zip\",\n",
    "                      sep=\";\",\n",
    "                      header=0,\n",
    "                      names=[\"gender\", \"name\", \"year\", \"births\"],\n",
    "                      converters={\"name\": str.title, \"gender\": mapping.get})\n",
    "    # clean\n",
    "    df = (df\n",
    "          .loc[lambda df_: (df_.name.str.len() > 1) & (df_.year != \"XXXX\") & ~(df_.name.str.startswith(\"_\"))]\n",
    "          #.query(\"\"\"(name.str.len() > 1) and (year != \"XXXX\") and not name.str.startswith(\"_\")\"\"\", engine='python')\n",
    "          .assign(year=lambda df_: df_.year.astype(int))\n",
    "          .loc[:, [\"year\", \"name\", \"gender\", \"births\"]]\n",
    "          .sort_values([\"year\", \"gender\", \"births\", \"name\"], ascending=[True, True, False, True])\n",
    "          .reset_index(drop=True)\n",
    "         )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_fr = df_names_fr()\n",
    "df_fr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with NA values\n",
    "def df_names_fr():\n",
    "    # genres\n",
    "    mapping = {1:\"M\", 2:\"F\"}\n",
    "    # read_csv\n",
    "    df = pd.read_csv(\"nat2021_csv.zip\",\n",
    "                      sep=\";\",\n",
    "                      header=0,\n",
    "                      names=[\"gender\", \"name\", \"year\", \"births\"],\n",
    "                      na_values={\"year\":\"XXXX\", \"name\":\"_PRENOMS_RARES\"},\n",
    "                      keep_default_na=False)\n",
    "    # clean\n",
    "    df = (df\n",
    "          .dropna()\n",
    "          .loc[lambda df_: df_.name.str.len() > 1]\n",
    "          .assign(year=lambda df_: df_.year.astype(int),\n",
    "                  name=lambda df_: df_.name.str.title(),\n",
    "                  gender=lambda df_: df_.gender.map(mapping)\n",
    "                 )\n",
    "          .loc[:, [\"year\", \"name\", \"gender\", \"births\"]]\n",
    "          .sort_values([\"year\", \"gender\", \"births\", \"name\"], ascending=[True, True, False, True])\n",
    "          .reset_index(drop=True)\n",
    "         )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_fr = df_names_fr()\n",
    "df_fr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head\n",
    "df_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prénom NA\n",
    "df_fr.loc[df_fr['name']=='Na']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_csv default\n",
    "df = pd.read_csv(\"nat2021_csv.zip\",\n",
    "                  sep=';',\n",
    "                  header=0,\n",
    "                  names=[\"gender\", \"name\", \"year\", \"births\"]\n",
    "                )\n",
    "\n",
    "df[\"name\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_csv mode string sans NA par défaut\n",
    "df = pd.read_csv(\"nat2021_csv.zip\",\n",
    "                  sep=';',\n",
    "                  header=0,\n",
    "                  names=[\"gender\", \"name\", \"year\", \"births\"],\n",
    "                  dtype=str,\n",
    "                  na_values=\"\",\n",
    "                  keep_default_na=False\n",
    "                )\n",
    "\n",
    "df[\"name\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use functools.partial\n",
    "from functools import partial\n",
    "\n",
    "load_raw_csv = partial(pd.read_csv, dtype=str, na_values=\"\", keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage of load_raw_csv\n",
    "(load_raw_csv(\"nat2021_csv.zip\", sep=\";\")\n",
    " .isna()\n",
    " .sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capitalize\n",
    "\"JEAN-MARIE\".capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title\n",
    "\"JEAN-MARIE\".title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Taux de change\n",
    "\n",
    "On va s'intéresser au dataset des cours des devises de la Banque de France :  http://webstat.banque-france.fr/fr/browseBox.do?node=5385566\n",
    "\n",
    "Les données sont dans le fichier \"Webstat_Export.csv\".\n",
    "\n",
    "L'idée est de charger les données, de les nettoyer et de pouvoir accéder aux cours de certaines devises à partir de leur code ISO3. On retiendra uniquement les colonnes se terminant effectivement par un code ISO3 entre parenthèses. Par ex., \"Dollar des Etats-Unis (USD)\".\n",
    "\n",
    "Implémenter une fonction qui produit un DataFrame avec les taux de change par date pour une liste de codes ISO3 de devises passée en argument. L'index du DataFrame doit correspondre aux dates (voir la fonction `pd.to_datetime()` avec le format '%d/%m/%Y') et doit être trié par ordre croissant. Les colonnes du DataFrame doivent correspondre aux devises sélectionnées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_taux_change(devises):\n",
    "    df = pd.read_csv(\"Webstat_Export.csv\",\n",
    "                     sep=\";\",\n",
    "                     na_values='-',\n",
    "                     decimal=',',\n",
    "                     skiprows=range(1, 6),  # le skiprows permet à l'option \"decimal\" de fonctionner\n",
    "                     converters={0: lambda x: pd.to_datetime(x, format='%d/%m/%Y', errors='ignore')})\n",
    "\n",
    "    # extraction des codes iso3 des monnaies\n",
    "    iso3 = pd.Series(df.columns.tolist()).str.extract('\\(([A-Z]{3})\\)$', expand=False)\n",
    "    iso3.iloc[0] = 'Date'\n",
    "    \n",
    "    df = (df.rename(columns=dict(zip(df.columns, iso3)))\n",
    "          .loc[:, ['Date'] + devises]\n",
    "          .dropna()\n",
    "          .set_index('Date')\n",
    "          .sort_index()\n",
    "         )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemple\n",
    "df_tx = df_taux_change([\"CHF\", \"GBP\", \"USD\"])\n",
    "df_tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head\n",
    "df_tx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index\n",
    "df_tx.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class Session3Tests(unittest.TestCase):\n",
    "    def test_df_names_us(self):\n",
    "        df = df_names_us()\n",
    "        # colonnes\n",
    "        self.assertEqual(list(df.columns), [\"year\", \"name\", \"gender\", \"births\"])\n",
    "        # lignes\n",
    "        self.assertEqual(len(df), 2052781)\n",
    "        # index\n",
    "        self.assertTrue(isinstance(df.index, pd.core.indexes.range.RangeIndex))\n",
    "        # test NaN\n",
    "        self.assertTrue(df.loc[df.isnull().any(axis=1)].empty)\n",
    "        \n",
    "    def test_df_names_fr(self):\n",
    "        df = df_names_fr()\n",
    "        # colonnes\n",
    "        self.assertEqual(list(df.columns), [\"year\", \"name\", \"gender\", \"births\"])\n",
    "        # lignes\n",
    "        self.assertEqual(len(df), 648330)\n",
    "        # index\n",
    "        self.assertTrue(isinstance(df.index, pd.RangeIndex))\n",
    "        # test names\n",
    "        self.assertTrue(df.loc[df.name.str.contains(r\"^[A-Z]+$\")].empty)\n",
    "        self.assertTrue(df.loc[df.name.str.contains(r\"-[a-z]+$\")].empty)\n",
    "        # test gender\n",
    "        self.assertEqual(len(df), len(df.loc[df.gender==\"F\"]) + len(df.loc[df.gender=='M']))\n",
    "        # test NaN\n",
    "        self.assertTrue(df.loc[df.isnull().any(axis=1)].empty)\n",
    "\n",
    "    def test_df_taux_change(self):\n",
    "        df = df_taux_change([\"CHF\", \"GBP\", \"USD\"])\n",
    "        # colonnes\n",
    "        self.assertEqual(list(df.columns), [\"CHF\", \"GBP\", \"USD\"])\n",
    "        # index\n",
    "        self.assertTrue(isinstance(df.index, pd.DatetimeIndex))\n",
    "        # index trié\n",
    "        self.assertEqual(list(df.index.argsort()), list(range(len(df))))\n",
    "        # types taux\n",
    "        self.assertTrue((df.dtypes == float).all())\n",
    "        # test NaN\n",
    "        self.assertTrue(df.loc[df.isnull().any(axis=1)].empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run tests\n",
    "def run_tests():\n",
    "    test_suite = unittest.makeSuite(Session3Tests)\n",
    "    runner = unittest.TextTestRunner(verbosity=2)\n",
    "    runner.run(test_suite)\n",
    "    \n",
    "run_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session 5 - Un peu de Data Science...\n",
    "\n",
    "**Question n° 1**\n",
    "\n",
    "Pourquoi le `value_counts()` du \"gender\" donne-t-il un tel écart entre \"F\" et \"M\" ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts du gender US\n",
    "\n",
    "df_us[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts du gender FR\n",
    "\n",
    "df_fr[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pct_change\n",
    "\n",
    "df_us[\"gender\"].value_counts().pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pct_change\n",
    "\n",
    "df_fr[\"gender\"].value_counts().pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question n° 2**\n",
    "\n",
    "Pourquoi le `value_counts()̀  du \"name\" donne-t-il ce résultat ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts du gender US\n",
    "\n",
    "df_us[\"name\"].value_counts().head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts du gender FR\n",
    "\n",
    "df_fr[\"name\"].value_counts().head(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question n° 3**\n",
    "\n",
    "Pourquoi le `value_counts()` du \"year\" donne-t-il ce résultat ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts du gender US\n",
    "\n",
    "df_us[\"year\"].value_counts().head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts du gender FR\n",
    "\n",
    "df_fr[\"year\"].value_counts().head(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice n° 1**\n",
    "\n",
    "Donnez le prénom qui a été le plus donné lors d'une année."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice n° 2**\n",
    "\n",
    "Donnez la liste des prénoms qui contiennent dans l'ordre a, e, i, o et u (US) ou bien a, e, i et o (FR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthodes de reshaping (1)\n",
    "\n",
    "#### pivot_table\n",
    "\n",
    "La méthode `pivot_table()` prend en argument :\n",
    "- index : colonne(s) dont les valeurs vont servir d'index à la table pivot\n",
    "- columns : colonne(s) dont les valeurs vont servir de colonnes à la table pivot\n",
    "- values : valeurs qui doivent être agrégées selon les modalités de la colonne passée en \"index\" et de la colonne passée en \"columns\"\n",
    "- aggfunc : fonction d'aggrégation des values, par défaut 'mean', 'median', 'min', 'max', 'count', 'sum', 'nunique', et n'importe quelle lambda ou liste de fonctions\n",
    "- fill_value : valeur en cas d'absence des modalités croisées \n",
    "\n",
    "On obtient `NaN` s'il n'y a pas d'occurence croisée.\n",
    "\n",
    "Excel = tableau croisé dynamique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemple\n",
    "df = pd.DataFrame([{'A': 1,'B': 1, 'C': 1},\n",
    "                   {'A': 1,'B': 1, 'C': 2},\n",
    "                   {'A': 1,'B': 2, 'C': -1},\n",
    "                   {'A': 2,'B': 1, 'C': 4},\n",
    "                   {'A': 2,'B': 1, 'C': 5},\n",
    "                  ])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemple\n",
    "tab = df.pivot_table(values='C',\n",
    "                     index='A',\n",
    "                     columns='B')\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemple\n",
    "df.pivot_table(values='C',\n",
    "              index='A',\n",
    "              columns='B',\n",
    "              aggfunc=tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemple\n",
    "df.pivot_table(values='C',\n",
    "              index='A',\n",
    "              columns='B',\n",
    "              aggfunc='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice n° 3**\n",
    "\n",
    "Calculez une table pivot avec le nombre total de naissances par année et par genre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice n° 4**\n",
    "\n",
    "Calculez une table pivot avec la diversité des prénoms (nombre de prénoms distincts) par année et par genre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### crosstab\n",
    "\n",
    "`crosstab()` est une fonction de reshaping qui prend 2 Series partageant le même index (ou 2 colonnes d'un DataFrame) en argument et produit le décompte croisé des occurrences.\n",
    "\n",
    "On obtient 0 s'il n'y a pas d'occurence croisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemple\n",
    "pd.crosstab(df['A'], df['B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial\n",
    "df_us['initial'] = df_us['name'].str[0].str.upper()\n",
    "# terminal\n",
    "df_us['terminal'] = df_us['name'].str[-1].str.upper()\n",
    "\n",
    "df_us.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crosstab\n",
    "pd.crosstab(df_us['initial'], df_us['terminal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot_table\n",
    "df_us.pivot_table(values='name',\n",
    "                  index='initial',\n",
    "                  columns='terminal',\n",
    "                  aggfunc='count',\n",
    "                  fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z x Z\n",
    "df_us.loc[(df_us['initial'] == 'Z') & (df_us['terminal'] == 'Z')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z x Z\n",
    "df_us.loc[df_us['name'].str.startswith('Z') & df_us['name'].str.endswith('z')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
